{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 3 â€’  Classification\n",
    "\n",
    "**Author:** Theodor Tveit Husefest, Arlid Madshaven, Mathies Pollas Bjerg\n",
    "**Due date:** 08.05.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-03-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST \n",
    "*Add your implementation and discussion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size = 16, \n",
    "                    valid_size = 0.2,\n",
    "                    shuffle= True):\n",
    "    \"\"\"\n",
    "    Helper function to create online dataloaders to use in pytorch network.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([transforms.RandomRotation(180),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5), (0.5))])\n",
    "    train_dataset = datasets.MNIST('MNIST_data/', download= True, train= True, transform = transform)\n",
    "    \n",
    "    test_dataset = datasets.MNIST('MNIST_data/', download= True, train= False, transform = transform)\n",
    "    \n",
    "    num_train = len(train_dataset)\n",
    "    indicies = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(indicies)\n",
    "        \n",
    "    train_ix, val_ix = indicies[split:], indicies[:split]\n",
    "    train_sampler = data.SubsetRandomSampler(train_ix)\n",
    "    val_sampler = data.SubsetRandomSampler(val_ix)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, sampler= train_sampler)\n",
    "    val_loader = data.DataLoader(train_dataset, batch_size=batch_size, sampler= val_sampler)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size = batch_size)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self,).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = 4, kernel_size= 3, padding= 1)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 4, out_channels = 8, kernel_size= 3, padding= 1)\n",
    "        self.fc1 = nn.Linear(8*7*7, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, 8*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(x)\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on_dataloader(net, dataloader):\n",
    "    \"\"\"\n",
    "    Returns accuracy on a given dataloader\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():    \n",
    "        for images, labels in val_loader:\n",
    "\n",
    "            output = net(images)\n",
    "            predicted = (F.softmax(output).data).max(1)[1]\n",
    "            correct += (labels == predicted).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return 100*(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "EPOCH 0.\n",
      "Accuracy on validation set 82.85833333333333\n",
      "Finished epoch after 21.574s\n",
      "Loss after epoch 0 was 2652.352029964328.\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 1.\n",
      "Finished epoch after 19.299s\n",
      "Loss after epoch 1 was 1195.18766342476.\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 2.\n",
      "Accuracy on validation set 91.65833333333333\n",
      "Finished epoch after 22.197s\n",
      "Loss after epoch 2 was 890.5126202148385.\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 3.\n",
      "Finished epoch after 19.411s\n",
      "Loss after epoch 3 was 767.8573302775621.\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "EPOCH 4.\n",
      "Accuracy on validation set 92.80000000000001\n",
      "Finished epoch after 21.888s\n",
      "Loss after epoch 4 was 680.3304076124914.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 5\n",
    "eval_every = 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    accuracy = 0\n",
    "    tic = time.time()\n",
    "    net.train()\n",
    "    \n",
    "    print('--------------------------------------------------')\n",
    "    print('EPOCH {}.'.format(e))\n",
    "\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        accuracy = validate_on_dataloader(net, val_loader)\n",
    "        print('Accuracy on validation set {}'.format(accuracy))\n",
    "\n",
    "\n",
    "        \n",
    "    toc = time.time()\n",
    "    print('Finished epoch after {}s'.format(np.around(toc-tic, 3)))\n",
    "    print('Loss after epoch {} was {}.'.format(e, epoch_loss))\n",
    "    print('--------------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset: 93.25833333333333\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = validate_on_dataloader(net, test_loader)\n",
    "\n",
    "print('Accuracy on testset:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n",
      "Predicted: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOlUlEQVR4nO3dfYxUZZbH8d/hTQKMBpZGGsfYs4Q/FjcuM6mQNWwmrKMD+g+OyZjhj1GjCWMCBCOIBhOHGE1wdRY3asYwC4JmlJAwxpcQF0NIzCRmtDSIKHFFRd5aaBZ1GEmEhrN/9GW3B/s+t6hbb8P5fpJOVd9TT92T6v71ra6nbj3m7gJw4RvW7gYAtAZhB4Ig7EAQhB0IgrADQYxo5c4mTpzoPT09rdwlEMrevXt19OhRG6pWKuxmNlfSf0gaLuk/3X1V6vY9PT2qVqtldgkgoVKp5NbqfhpvZsMlPSXpeknTJc03s+n13h+A5irzP/tMSXvc/VN3Pylpo6R5jWkLQKOVCftlkvYP+v5Atu2vmNkCM6uaWbWvr6/E7gCUUSbsQ70I8J333rr7GnevuHulq6urxO4AlFEm7AckXT7o++9LOlSuHQDNUibsb0uaZmY/MLNRkn4h6eXGtAWg0eqeenP3fjNbJOm/NDD1ts7dP2hYZwAaqtQ8u7tvkbSlQb0AaCLeLgsEQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IotSSzWa2V9JxSacl9bt7pRFNAWi8UmHP/Ku7H23A/QBoIp7GA0GUDbtL2mpm75jZgqFuYGYLzKxqZtW+vr6SuwNQr7Jhn+XuP5J0vaSFZvbjc2/g7mvcveLula6urpK7A1CvUmF390PZ5RFJL0qa2YimADRe3WE3s7Fm9r2z1yX9VNKuRjUGoLHKvBp/qaQXzezs/Tzv7q81pKu/MadPn07Whw8f3qJOgHx1h93dP5X0Tw3sBUATMfUGBEHYgSAIOxAEYQeCIOxAEI04EeaCcOLEibrHjhs3LllfsmRJsr5p06Zk/aOPPkrWR4zI/zGOHj06OfbMmTPJ+rBhHA8uFPwkgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tkzY8aMSdbLnKb6+OOPJ+tTpkxJ1i+++OJkPTUXvmLFiuTYWbNmJetz5sxJ1vv7+5P11HsAPvnkk+TYqVOnJus4PxzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCIMPPsRR/3vGXLlmS9p6cnt1Y0B79nz55kvbe3N1kv46GHHio1/pJLLknWX3rppWT9nnvuya09//zzybFF5/E/99xzyXrK9u3bk/W1a9cm66+++mqyfueddybrW7duza3ddNNNybH14sgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0GEmWcvmgt/6623kvXUedtffPFFcuzOnTuT9SLz5s1L1j/77LNS95/y9ddfJ+uzZ8+u+76nTZtW91hJGjt2bLL+zTff5Nauvvrq5Njp06fX1dNZy5cvT9bdve77rnds4ZHdzNaZ2REz2zVo2wQze93MPs4ux9e1dwAtU8vT+PWS5p6z7T5J29x9mqRt2fcAOlhh2N39DUnHztk8T9KG7PoGSTc2uC8ADVbvC3SXunuvJGWXk/JuaGYLzKxqZtW+vr46dwegrKa/Gu/ua9y94u6Vrq6uZu8OQI56w37YzLolKbs80riWADRDvWF/WdKt2fVbJaXPcwTQdoXz7Gb2gqTZkiaa2QFJv5a0StImM7tD0j5JP29mk62QOr9YkiZPnpxb279/f3Js6pxuSXrmmWeS9QcffDBZv/fee3Nrhw4dSo5tttTnxhd95nyR1Dx6kTfffLPUvpsp9dkJkrRx48bc2rFj576W/v8Kw+7u83NKPykaC6Bz8HZZIAjCDgRB2IEgCDsQBGEHgghzimuRoo+S7u7uzq1de+21ybHPPvtssl70scMHDx5M1nft2pVbK3rXYtFHbBdZsmRJsr569ercWtHjMmlS7ruwJUnz5+dNFA1ITVkuW7YsOTb1867F5s2bk/VFixbl1spMCz722GO5NY7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE8+yZ9957L1l/7bXXcmtF8+xTpkxJ1k+dOpWsFzlz5kxu7dtvv02OTc33StLTTz+drI8ZMyZZT7nllluS9dRjLklffvllsv7555/n1hYvXpwcW+TkyZPJ+qhRo5L1dpxiy5EdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jgnj1zzTXXJOtz5567tmXtHn300WS9aM73iSeeSNaHDav/b/aJEyeS9aKlri+66KJkPXVO+QMPPJAcW+Yxl6Qrrrii1PiUonn0TsSRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ69Rqlzq6+77rrk2LvvvjtZX7hwYbJetLRxalnkIuvXr697rCStXLkyWb/ttttK3T8ap/DIbmbrzOyIme0atG2lmR00sx3Z1w3NbRNAWbU8jV8vaai3Mq129xnZV3o5FQBtVxh2d39D0rEW9AKgicq8QLfIzHZmT/PH593IzBaYWdXMqn19fSV2B6CMesP+W0lTJc2Q1CvpN3k3dPc17l5x90rRIoMAmqeusLv7YXc/7e5nJP1O0szGtgWg0eoKu5kNXs/2Z5Ly1wwG0BEKJ2jN7AVJsyVNNLMDkn4tabaZzZDkkvZK+lUTe+x4c+bMSda3bduWrD/11FOl6g8//HBubenSpcmxRedlX3nllcn6I488kqwvX748t1b0Gs4rr7ySrOP8FIbd3Yda8X5tE3oB0ES8XRYIgrADQRB2IAjCDgRB2IEgOMW1AZYtW5as33777cl60fTW4cOHk/UdO3bk1kaPHp0c++STTybrN998c7JerVaT9dTHXM+ePTs5Fo3FkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3b9nOKpWKF83L4rt6e3uT9dQ8/VdffZUcO3ny5GS97NLE+/bty62NHTs2Ofb48eOl9h1RpVJRtVq1oWoc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCM5nvwAcO5a/FN/999+fHLtu3bpkPTVPXlbRufKnTp1K1keOHNnIdi54HNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2f8GdHd31z124cKFpfa9atWqZL1oOenUks2LFy+uqyfUp/DIbmaXm9l2M9ttZh+Y2ZJs+wQze93MPs4uxze/XQD1quVpfL+kpe7+D5L+WdJCM5su6T5J29x9mqRt2fcAOlRh2N29193fza4fl7Rb0mWS5knakN1sg6Qbm9UkgPLO6wU6M+uR9ENJf5J0qbv3SgN/ECRNyhmzwMyqZlbt6+sr1y2AutUcdjMbJ2mzpLvc/c+1jnP3Ne5ecfdKV1dXPT0CaICawm5mIzUQ9N+7+x+yzYfNrDurd0s60pwWATRC4UdJm5lp4H/yY+5+16Dtj0r6H3dfZWb3SZrg7vnzLOKjpC9E/f39yfqHH36YW7vqqqsa3U54qY+SrmWefZakX0p638zOLgS+QtIqSZvM7A5J+yT9vBHNAmiOwrC7+x8lDfmXQtJPGtsOgGbh7bJAEIQdCIKwA0EQdiAIwg4EwSmuKGXEiPSvEHPpnYMjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFEYdjO73My2m9luM/vAzJZk21ea2UEz25F93dD8dgHUq5ZFIvolLXX3d83se5LeMbPXs9pqd3+see0BaJRa1mfvldSbXT9uZrslXdbsxgA01nn9z25mPZJ+KOlP2aZFZrbTzNaZ2ficMQvMrGpm1b6+vlLNAqhfzWE3s3GSNku6y93/LOm3kqZKmqGBI/9vhhrn7mvcveLula6urga0DKAeNYXdzEZqIOi/d/c/SJK7H3b30+5+RtLvJM1sXpsAyqrl1XiTtFbSbnf/90Hbuwfd7GeSdjW+PQCNUsur8bMk/VLS+2a2I9u2QtJ8M5shySXtlfSrpnQIoCFqeTX+j5JsiNKWxrcDoFl4Bx0QBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIc/fW7cysT9LngzZNlHS0ZQ2cn07trVP7kuitXo3s7Qp3H/Lz31oa9u/s3Kzq7pW2NZDQqb11al8SvdWrVb3xNB4IgrADQbQ77GvavP+UTu2tU/uS6K1eLemtrf+zA2iddh/ZAbQIYQeCaEvYzWyumX1kZnvM7L529JDHzPaa2fvZMtTVNveyzsyOmNmuQdsmmNnrZvZxdjnkGntt6q0jlvFOLDPe1seu3cuft/x/djMbLum/JV0n6YCktyXNd/cPW9pIDjPbK6ni7m1/A4aZ/VjSXyQ96+7/mG37N0nH3H1V9odyvLvf2yG9rZT0l3Yv452tVtQ9eJlxSTdKuk1tfOwSfd2sFjxu7Tiyz5S0x90/dfeTkjZKmteGPjqeu78h6dg5m+dJ2pBd36CBX5aWy+mtI7h7r7u/m10/LunsMuNtfewSfbVEO8J+maT9g74/oM5a790lbTWzd8xsQbubGcKl7t4rDfzySJrU5n7OVbiMdyuds8x4xzx29Sx/XlY7wj7UUlKdNP83y91/JOl6SQuzp6uoTU3LeLfKEMuMd4R6lz8vqx1hPyDp8kHff1/SoTb0MSR3P5RdHpH0ojpvKerDZ1fQzS6PtLmf/9NJy3gPtcy4OuCxa+fy5+0I+9uSppnZD8xslKRfSHq5DX18h5mNzV44kZmNlfRTdd5S1C9LujW7fqukl9rYy1/plGW885YZV5sfu7Yvf+7uLf+SdIMGXpH/RNL97eghp6+/l/Re9vVBu3uT9IIGntad0sAzojsk/Z2kbZI+zi4ndFBvz0l6X9JODQSru029/YsG/jXcKWlH9nVDux+7RF8tedx4uywQBO+gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEg/hdp0nP+6DFh8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "img_nr = np.random.randint(16, size = 1)\n",
    "img, label = images[img_nr], labels[img_nr]\n",
    "\n",
    "plt.imshow(img.resize(28,28), cmap = \"Greys\")\n",
    "print('Label:', label.item())\n",
    "\n",
    "output = net(img)\n",
    "pred = (F.softmax(output).data).max(1)[1]\n",
    "print('Predicted:', pred.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Thoughts on Task 2\n",
    "\n",
    "As the group had more experience in PyTorch we chose to use this to implement the neural net, and it gave quite good performance.  \n",
    "We see that the neural net is performing very good with quite low complexity, and if we were to add for example convolutional layers we would get even better performance.  \n",
    "Compared to lab 2 where we had to pick out features and tune our algos, this is a lot easier and is probably performing a lot better than we could manage by doing this manually.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theshold_test_img(img):\n",
    "    img_mean = img.mean()\n",
    "    img[img < img_mean] = 0\n",
    "    img[img >= img_mean] = 255\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "img = PIL.Image.open(\"./data/candidates/im27.png\")\n",
    "img = PIL.ImageOps.invert(img)\n",
    "\n",
    "img = img.resize((28, 28), PIL.Image.ANTIALIAS)\n",
    "img = np.asarray(img)\n",
    "img = rgb2gray(img)\n",
    "img = theshold_test_img(img)\n",
    "\n",
    "plt.imshow(img, cmap= \"Greys\")\n",
    "img = torch.from_numpy(img.astype(np.float32))\n",
    "img = img.unsqueeze(0)\n",
    "img = img.unsqueeze(0)\n",
    "output = net(img)\n",
    "pred = (F.softmax(output).data).max(1)[1]\n",
    "print('Predicted:', pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
