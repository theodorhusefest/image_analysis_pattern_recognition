{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatorsDataset(Dataset):\n",
    "    \"\"\" Custom Dataset for Operators\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, csv_file, transform = None, grayscale = True):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.grayscale = grayscale\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.loc[idx].path)\n",
    "        image = io.imread(img_name)\n",
    "\n",
    "        label = self.dataframe.loc[idx].label\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(image)\n",
    "        \n",
    "        if self.grayscale:\n",
    "            image = rgb2gray(image)\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        return (image, label)\n",
    "\n",
    "dataset = OperatorsDataset(\"./data/operators\", \"./data/operators/datasheet.csv\", transform = transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "valid_size = 0.2\n",
    "shuffle = True\n",
    "random_seed = 1\n",
    "num_workers = 0\n",
    "pin_memory = 1\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "    num_workers=num_workers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" Init \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = self.forward(x)\n",
    "        return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on_dataloader(net, dataloader):\n",
    "    \"\"\"\n",
    "    Returns accuracy on a given dataloader\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():    \n",
    "        for images, labels in dataloader:\n",
    "\n",
    "            images.resize_(images.size()[0], 1024)\n",
    "\n",
    "            output = net(images)\n",
    "            predicted = (F.softmax(output).data).max(1)[1]\n",
    "            correct += (labels == predicted).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return 100*(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 0\n",
      "Loss on current epoch: 390.3877424001694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/anaconda3/envs/iapr/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 71.81\n",
      "Accuracy on validation set 70.99\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 10\n",
      "Loss on current epoch: 117.98741360753775\n",
      "Accuracy on train set 87.22\n",
      "Accuracy on validation set 86.69\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 20\n",
      "Loss on current epoch: 80.93988785240799\n",
      "Accuracy on train set 91.74\n",
      "Accuracy on validation set 89.08\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 30\n",
      "Loss on current epoch: 62.47345581650734\n",
      "Accuracy on train set 95.23\n",
      "Accuracy on validation set 92.15\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 40\n",
      "Loss on current epoch: 49.92151807527989\n",
      "Accuracy on train set 96.0\n",
      "Accuracy on validation set 91.47\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 50\n",
      "Loss on current epoch: 39.35477989667561\n",
      "Accuracy on train set 97.36\n",
      "Accuracy on validation set 93.86\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 60\n",
      "Loss on current epoch: 33.23464342451189\n",
      "Accuracy on train set 98.13\n",
      "Accuracy on validation set 93.17\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 70\n",
      "Loss on current epoch: 25.64236627734499\n",
      "Accuracy on train set 98.21\n",
      "Accuracy on validation set 92.49\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 80\n",
      "Loss on current epoch: 20.67055618169252\n",
      "Accuracy on train set 98.64\n",
      "Accuracy on validation set 93.17\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Started on epoch 90\n",
      "Loss on current epoch: 16.525641372893006\n",
      "Accuracy on train set 99.49\n",
      "Accuracy on validation set 93.86\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = OperatorNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.00005)\n",
    "\n",
    "epochs = 100\n",
    "eval_every = 10\n",
    "\n",
    "for e in range(epochs): \n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        \n",
    "        images.resize_(images.size()[0], 1024)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    if e % eval_every == 0:\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(\"\\nStarted on epoch {}\".format(e))\n",
    "        print(\"Loss on current epoch: {}\".format(running_loss))\n",
    "        \n",
    "        accuracy_train = validate_on_dataloader(net, train_loader)\n",
    "        print(\"Accuracy on train set {}\".format(np.around(accuracy_train, 2)))\n",
    "        \n",
    "        accuracy_val = validate_on_dataloader(net, valid_loader)\n",
    "        print(\"Accuracy on validation set {}\".format(np.around(accuracy_val, 2)))\n",
    "        print(\"----------------------------------------\\n\")\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Equals\n",
      "Predicted: Equals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/anaconda3/envs/iapr/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_map = {0: \"Plus\", 1: \"Minus\", 2: \"Multiplication\", 3: \"Divide\", 4: \"Equals\"}\n",
    "\n",
    "dataiter = iter(valid_loader)\n",
    "images, labels = dataiter.next()\n",
    "img_nr = np.random.randint(4, size = 1)\n",
    "img, label = images[img_nr], labels[img_nr]\n",
    "\n",
    "plt.imshow(img.resize(32,32), cmap = \"Greys\")\n",
    "print('Label:', label_map[label.item()])\n",
    "\n",
    "output = net(img.resize(1, 1024))\n",
    "pred = (F.softmax(output).data).max(1)[1]\n",
    "print('Predicted:', label_map[pred.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a33a3c910>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "operators = Image.open(\"./data/original_operators.png\")\n",
    "img = np.asarray(operators)\n",
    "img_grey = rgb2gray(img)\n",
    "plt.imshow(img_grey, cmap = \"Greys\")\n",
    "def extract_operators(img):\n",
    "    N = 316\n",
    "    plus = img[:, 0:N]\n",
    "    equals = img[:, N:2*N]\n",
    "    min_offset = 75\n",
    "    minus = img[:, 2*N + min_offset :3*N + min_offset]\n",
    "    div_offset = 125\n",
    "    div = img[:, 3*N + div_offset:4*N + div_offset]\n",
    "    mul_offset = 155\n",
    "    mul = img[:, 4*N + mul_offset:-1]\n",
    "    return [plus, minus, div, mul, equals]\n",
    "operators = extract_operators(img_grey)\n",
    "\n",
    "operators = [resize(operators[i], (32, 32)) for i in range(len(operators))]\n",
    "plt.imshow(operators[0], cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "i = 0\n",
    "for operator in operators:\n",
    "    im = Image.fromarray(np.uint8(cm.gist_earth(operator)*255))\n",
    "    im.save(\"./data/im{}.png\".format(str(i)))\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x630602f50>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "op_tensors = [torch.from_numpy(operators[i].astype(np.float32)) for i in range(len(operators))]\n",
    "plt.imshow(op_tensors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Minus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/anaconda3/envs/iapr/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "output = net(op_tensors[1].resize(1, 1024))\n",
    "pred = (F.softmax(output).data).max(1)[1]\n",
    "print('Predicted:', label_map[pred.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
